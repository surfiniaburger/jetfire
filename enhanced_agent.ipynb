{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# AI Agents for Engineers (Evolution of AI Agents)\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/workshops/ai-agents/ai_agents_for_engineers.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Kristopher Overholt](https://github.com/koverholt) [Holt Skinner](https://github.com/holtskinner)|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates 3 different approaches to generating essays using the [Gemini Developer API](https://ai.google.dev/gemini-api/docs) or [Gemini API in Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview). Each method illustrates a distinct paradigm for running AI Agents in differing levels of complexity.\n",
        "\n",
        "1. Zero-Shot Approach with the Gemini API\n",
        "2. Step-by-Step Approach With LangChain\n",
        "3. Iterative, AI-Agent Approach with LangGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Gemini SDK and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "tFy3H3aPgx12",
        "outputId": "5fddb36c-2406-410f-e88e-2edfd0883563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/124.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet \\\n",
        "    google-genai \\\n",
        "    langgraph \\\n",
        "    langchain \\\n",
        "    langchain-google-genai \\\n",
        "    langchain-google-vertexai \\\n",
        "    langchain-groq \\\n",
        "    langchain-community \\\n",
        "    tavily-python \\\n",
        "    pydantic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall google-generativeai google-ai-generativelanguage -y"
      ],
      "metadata": {
        "id": "9J8w2x-ewX80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai==0.8.4 google-ai-generativelanguage==0.6.15"
      ],
      "metadata": {
        "id": "0TVdJXXjwaeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1824bd79df4"
      },
      "source": [
        "### Configure Tavily\n",
        "\n",
        "Get an API key for [Tavily](https://tavily.com/), a web search API for Generative AI models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5df2f86c691f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"YOUR_API_KEY_HERE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e00844b64cf7"
      },
      "outputs": [],
      "source": [
        "# If your API Keys are in Colab Secrets\n",
        "import sys\n",
        "import os\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import userdata\n",
        "\n",
        "    os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0781fd4c9001"
      },
      "source": [
        "### Configure Gemini Developer API\n",
        "\n",
        "Get API keys from [Google AI Studio](https://ai.google.dev/gemini-api/docs/api-key) and [Tavily](https://tavily.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2d2ecd0e96d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY_HERE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "nvuDx1V6buOQ"
      },
      "outputs": [],
      "source": [
        "# If your API Keys are in Colab Secrets\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import userdata\n",
        "\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "    os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ffb0f859dde"
      },
      "source": [
        "### Configure Vertex AI\n",
        "\n",
        "**Use a Google Cloud Project:** This requires enabling the Vertex AI API in your Google Cloud project.\n",
        "\n",
        "[Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "885a3c84ddac"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c80118166880"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"starscraper\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdvJRUWRNGHE"
      },
      "source": [
        "## Generating Essays Using a Zero-Shot Approach with the Gemini API\n",
        "\n",
        "With just a single call to the `generate_content` method, users can create detailed, structured essays on any topic by leveraging state-of-the-art language models such as Gemini 1.5 Pro or Gemini 1.5 Flash.\n",
        "\n",
        "<img src=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/workshops/ai-agents/1-prompt-essay.png?raw=1\" width=\"350px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5303c05f7aa6"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6fc324893334"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4631829d00c8"
      },
      "source": [
        "### Create Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "898c62c59d40"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b87f1f593d5"
      },
      "source": [
        "Verify which API you are using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "84c16a5f3f33",
        "outputId": "161d7eac-d600-4a7f-f828-918f0cb2fbb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Vertex AI in express mode with API key: AIzaS...uWJxQ\n"
          ]
        }
      ],
      "source": [
        "if not client.vertexai:\n",
        "    print(f\"Using Gemini Developer API.\")\n",
        "elif client._api_client.project:\n",
        "    print(\n",
        "        f\"Using Vertex AI with project: {client._api_client.project} in location: {client._api_client.location}\"\n",
        "    )\n",
        "elif client._api_client.api_key:\n",
        "    print(\n",
        "        f\"Using Vertex AI in express mode with API key: {client._api_client.api_key[:5]}...{client._api_client.api_key[-5:]}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e43229f3ad4f"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cf93d5f0ce00"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-pro-exp-02-05\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbcd4f57190f"
      },
      "source": [
        "### Make an API call to generate the essay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "520e23ea4332"
      },
      "source": [
        "---\n",
        "\n",
        "However, what if we ask the model to write an essay about an event that happened more recently and the LLM doesn't inherently know about that event?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "764ce71aecd5"
      },
      "source": [
        "In this case, the model had no information about these recent events and was unable to write an effective essay."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16aafc60d80b"
      },
      "source": [
        "## Generating Essays Using a Step-by-Step Approach With LangChain\n",
        "\n",
        "This step demonstrates how to build an essay-writing pipeline using [LangChain](https://www.langchain.com/), the [Gemini API in Google AI Studio](https://ai.google.dev/gemini-api/docs), and [Tavily](https://tavily.com/) for search.\n",
        "\n",
        "By combining these tools, we create a seamless workflow that plans an essay outline, performs web searches for relevant information, and generates a complete essay draft based on the collected data.\n",
        "\n",
        "This solution showcases the power of chaining LLM models and external tools to tackle complex tasks with minimal human intervention, providing a robust approach to automated content generation.\n",
        "\n",
        "<img src=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/workshops/ai-agents/2-langchain-essay.png?raw=1\" width=\"550px\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85666976a359"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "29d6e42d27ae"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "from langchain import LLMChain\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "from langchain_groq import ChatGroq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43392590b1d8"
      },
      "source": [
        "### Initialize Gemini model & search tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ee8707e1867"
      },
      "source": [
        "### Define prompt templates and Runnables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "a09a6a6d1f36"
      },
      "outputs": [],
      "source": [
        "# Planning: Create an outline for the essay\n",
        "outline_template = ChatPromptTemplate.from_template(\n",
        "    \"Create a detailed outline for an essay on {topic}\"\n",
        ")\n",
        "\n",
        "\n",
        "# Research: Web search\n",
        "def research_fn(topic):\n",
        "    response = tavily_tool.invoke({\"query\": topic})\n",
        "    return \"\\n\".join([f\"- {result['content']}\" for result in response])\n",
        "\n",
        "\n",
        "# Writing: Write the essay based on outline and research\n",
        "writing_template = ChatPromptTemplate.from_template(\n",
        "    \"Based on the following outline and research, write a 3-paragraph essay on '{topic}':\\n\\nOutline:\\n{outline}\\n\\nResearch:\\n{research}\\n\\nEssay:\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a18006523f7"
      },
      "source": [
        "### Define the Runnable Chain using [LangChain Expression Language (LCEL)](https://python.langchain.com/docs/how_to/#langchain-expression-language-lcel)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In a cell before this one, make sure to import genai and initialize client\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "\n",
        "MODEL_ID = \"gemini-2.0-pro-exp-02-05\"\n",
        "prompt = \"Write a 3-paragraph essay about the impacts of Hurricane Helene and Hurricane Milton in 2024.\""
      ],
      "metadata": {
        "id": "vuxY3rte0Mrw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = ChatGoogleGenerativeAI(model=MODEL_ID, temperature=0)\n",
        "#model = ChatGroq(temperature=0, model_name=\"llama-3.3-70b-versatile\")\n",
        "tavily_tool = TavilySearchResults(max_results=5)"
      ],
      "metadata": {
        "id": "u6s6WqIH0Ynh"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "839fc48dd408"
      },
      "source": [
        "### Generate the essay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "\n",
        "# Initialize both models\n",
        "google_model = ChatGoogleGenerativeAI(model=MODEL_ID, temperature=0)\n",
        "groq_model = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0)\n",
        "\n",
        "# Create primary and backup chains\n",
        "primary_outline_chain = LLMChain(llm=google_model, prompt=outline_template)\n",
        "backup_outline_chain = LLMChain(llm=groq_model, prompt=outline_template)\n",
        "\n",
        "primary_writing_chain = LLMChain(llm=google_model, prompt=writing_template)\n",
        "backup_writing_chain = LLMChain(llm=groq_model, prompt=writing_template)\n",
        "\n",
        "# Create fallback chains using the RunnableBranch approach\n",
        "outline_chain = primary_outline_chain.with_fallbacks([backup_outline_chain])\n",
        "writing_chain = primary_writing_chain.with_fallbacks([backup_writing_chain])\n",
        "\n",
        "# Use the pipe operator to combine chains\n",
        "chain = (\n",
        "    outline_chain\n",
        "    | (\n",
        "        lambda result: {\n",
        "            \"topic\": result[\"topic\"],\n",
        "            \"outline\": result[\"text\"],\n",
        "            \"research\": research_fn(result[\"topic\"]),\n",
        "        }\n",
        "    )\n",
        "    | writing_chain\n",
        "    | (lambda result: result[\"text\"])  # Extract the essay text from the final result\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "QPp1OchQLdr3"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "a76f80ceec98",
        "outputId": "746a2eef-c935-4d27-a1e6-1f7ca9b04f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The 2024 hurricane season was marked by two devastating storms, Hurricane Helene and Hurricane Milton, which brought widespread destruction and disruption to communities in the United States. Hurricane Helene, a large and catastrophic tropical cyclone, made landfall in northwestern Florida on September 26, 2024, and went on to affect several states, including Tennessee, Georgia, and North Carolina. The storm's high winds and flooding resulted in the loss of over 230 lives, making it the deadliest hurricane to strike the U.S. since Hurricane Maria in 2017. Hurricane Milton, which made landfall on October 9, 2024, also caused significant damage and disruption, with over 3 million customers losing power and around 150 tornado warnings being issued.\n\nThe impacts of Hurricane Helene and Hurricane Milton were far-reaching and multifaceted. In addition to the loss of life, the storms caused extensive damage to infrastructure, including buildings, roads, and bridges. The flooding and storm surges associated with the storms contaminated wells, damaged homes, and disrupted communication systems. The human impacts of the storms were also significant, with many people forced to evacuate their homes and seek shelter elsewhere. The economic losses caused by the storms were substantial, with estimates suggesting that both Hurricane Helene and Hurricane Milton will be $50 billion disasters, ranking among the most costly storms in history. The storms also had a significant impact on the environment, with experts warning that the region must improve its disaster preparedness and mitigation measures to reduce the risk of similar disasters in the future.\n\nIn the aftermath of Hurricane Helene and Hurricane Milton, emergency relief efforts and aid distribution were critical in supporting affected communities. Long-term recovery and rebuilding efforts are ongoing, with a focus on restoring damaged infrastructure and supporting businesses and industries affected by the storms. The experiences of Hurricane Helene and Hurricane Milton serve as a reminder of the importance of preparedness and mitigation measures in reducing the impacts of future hurricanes. As the world continues to grapple with the challenges of climate-related disasters, it is essential that we learn from the lessons of these storms and work towards building more resilient and sustainable communities. By doing so, we can reduce the risk of similar disasters in the future and create a safer and more secure environment for all."
          },
          "metadata": {}
        }
      ],
      "source": [
        "essay = chain.invoke({\"topic\": prompt})\n",
        "display(Markdown(essay))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "294d3b7c43b2"
      },
      "source": [
        "## Generating Essays Using an Iterative, AI-Agent Approach with LangGraph\n",
        "\n",
        "This section demonstrates how to build a [LangGraph](https://langchain-ai.github.io/langgraph/)-powered AI agent to generate, revise, and critique essays using large language models such as Google's [Gemini API in Google AI Studio](https://ai.google.dev/gemini-api/docs) or the [Gemini API in Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/overview). The LangGraph code was adapted from the awesome DeepLearning.AI course on [AI Agents in LangGraph](https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/).\n",
        "\n",
        "By defining a structured state flow with nodes such as \"Planner,\" \"Research Plan,\" \"Generate,\" \"Reflect,\" and \"Research Critique,\" the system iteratively creates an essay on a given topic, incorporates feedback, and provides research-backed insights.\n",
        "\n",
        "<img src=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/workshops/ai-agents/3-langgraph-essay.png?raw=1\" width=\"900px\">\n",
        "\n",
        "The workflow enables automated essay generation with revision controls, making it ideal for structured writing tasks or educational use cases. Additionally, the notebook uses external search tools to gather and integrate real-time information into the essay content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8e41763086f"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "52fbe2cb7be7"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "# Common libraries\n",
        "from IPython.display import Image, Markdown, display\n",
        "\n",
        "# LangChain and LangGraph components\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# LangChain integrations for Gemini API in Google AI Studio and Vertex AI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "# Typing utilities for data validation and schema definitions\n",
        "from pydantic.v1 import BaseModel\n",
        "\n",
        "# Tavily client for performing web searches\n",
        "from tavily import TavilyClient\n",
        "\n",
        "import time\n",
        "import google"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc6ae1fac44f"
      },
      "source": [
        "### Initialize agent memory, agent state, and schema for search queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "6b92f7bab46d"
      },
      "outputs": [],
      "source": [
        "# Initialize agent memory\n",
        "memory = MemorySaver()\n",
        "\n",
        "\n",
        "# Define the agent's state\n",
        "class AgentState(TypedDict):\n",
        "    task: str\n",
        "    plan: str\n",
        "    draft: str\n",
        "    critique: str\n",
        "    content: list[str]\n",
        "    revision_number: int\n",
        "    max_revisions: int\n",
        "\n",
        "\n",
        "# Define a schema for search queries\n",
        "class Queries(BaseModel):\n",
        "    \"\"\"Variants of query to search for\"\"\"\n",
        "\n",
        "    queries: list[str]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9660e58afab"
      },
      "source": [
        "### Initialize Gemini model and search tool\n",
        "\n",
        "Remember to set the environment variables `GOOGLE_API_KEY` and `TAVILY_API_KEY`. And configure credentials for Vertex AI if you switch to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "ec96b00bb67f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize Tavily client for performing web searches\n",
        "tavily = TavilyClient()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d94dc64d3846"
      },
      "source": [
        "### Define prompt templates for each stage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2cc6f9b05d29"
      },
      "outputs": [],
      "source": [
        "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay.\n",
        "Write such an outline for the user provided topic. Give an outline of the essay along with any\n",
        "relevant notes or instructions for the sections.\"\"\"\n",
        "\n",
        "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 3-paragraph essays.\n",
        "Generate the best essay possible for the user's request and the initial outline.\n",
        "If the user provides critique, respond with a revised version of your previous attempts.\n",
        "Use Markdown formatting to specify a title and section headers for each paragraph.\n",
        "Utilize all of the information below as needed:\n",
        "---\n",
        "{content}\"\"\"\n",
        "\n",
        "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission.\n",
        "Generate critique and recommendations for the user's submission.\n",
        "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\"\n",
        "\n",
        "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can\n",
        "be used when writing the following essay. Generate a list of search queries that will gather\n",
        "any relevant information. Only generate 3 queries max.\"\"\"\n",
        "\n",
        "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can\n",
        "be used when making any requested revisions (as outlined below).\n",
        "Generate a list of search queries that will gather any relevant information.\n",
        "Only generate 3 queries max.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility functions"
      ],
      "metadata": {
        "id": "jhxaAQv9XYdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def extract_entities(text):\n",
        "    \"\"\"Extract key entities from model output text\"\"\"\n",
        "    # Split the text into lines and filter out empty lines\n",
        "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
        "\n",
        "    # Look for patterns like lists, bullet points, or numbered items\n",
        "    entities = []\n",
        "    for line in lines:\n",
        "        # Remove common list markers\n",
        "        clean_line = line.lstrip('•-*#0123456789.)')\n",
        "        clean_line = clean_line.strip()\n",
        "        if clean_line:\n",
        "            entities.append(clean_line)\n",
        "\n",
        "    # If no structured list is found, use basic text splitting\n",
        "    if not entities:\n",
        "        # Split by commas, semicolons, or periods\n",
        "        for part in re.split(r'[,;.]', text):\n",
        "            part = part.strip()\n",
        "            if part and len(part) > 3:  # Avoid very short fragments\n",
        "                entities.append(part)\n",
        "\n",
        "    return entities\n",
        "\n",
        "def parse_claims(claims_text):\n",
        "    \"\"\"Extract individual claims from model-generated text\"\"\"\n",
        "    # Split text by newlines and bullet points\n",
        "    raw_claims = re.split(r'\\n|•|\\*|\\d+\\.', claims_text)\n",
        "\n",
        "    # Clean up each claim\n",
        "    claims = []\n",
        "    for claim in raw_claims:\n",
        "        claim = claim.strip()\n",
        "        if claim and len(claim) > 10:  # Avoid fragments\n",
        "            # Remove phrases like \"Claim:\" or \"Fact:\"\n",
        "            claim = re.sub(r'^(Claim|Fact|Statement):\\s*', '', claim, flags=re.IGNORECASE)\n",
        "            claims.append(claim)\n",
        "\n",
        "    return claims\n",
        "\n",
        "def extract_score(evaluation_text):\n",
        "    \"\"\"Extract a numerical credibility score from evaluation text\"\"\"\n",
        "    # Look for patterns like \"Score: 7/10\" or \"Credibility: 4 out of 5\"\n",
        "    score_pattern = r'(\\d+)(?:\\s*\\/\\s*|\\s+out\\s+of\\s+)(\\d+)'\n",
        "    match = re.search(score_pattern, evaluation_text)\n",
        "\n",
        "    if match:\n",
        "        score, scale = int(match.group(1)), int(match.group(2))\n",
        "        # Normalize to 0-100 scale\n",
        "        return (score / scale) * 100\n",
        "\n",
        "    # If no explicit score, do sentiment analysis on key phrases\n",
        "    positive_indicators = ['credible', 'reliable', 'authoritative', 'trustworthy', 'reputable']\n",
        "    negative_indicators = ['unreliable', 'questionable', 'biased', 'unverified', 'misleading']\n",
        "\n",
        "    score = 50  # Neutral starting point\n",
        "    for word in positive_indicators:\n",
        "        if word in evaluation_text.lower():\n",
        "            score += 10\n",
        "    for word in negative_indicators:\n",
        "        if word in evaluation_text.lower():\n",
        "            score -= 10\n",
        "\n",
        "    return max(0, min(100, score))  # Clamp between 0-100\n",
        "\n",
        "def parse_opportunities(visual_text):\n",
        "    \"\"\"Extract visual opportunity suggestions from text\"\"\"\n",
        "    # Split by numbered or bulleted items\n",
        "    opportunities = re.split(r'\\n\\s*\\d+\\.|\\n\\s*•|\\n\\s*\\*', visual_text)\n",
        "\n",
        "    # Clean up and filter\n",
        "    return [opp.strip() for opp in opportunities if opp.strip() and len(opp.strip()) > 10]\n",
        "\n",
        "def determine_visual_type(spec_text):\n",
        "    \"\"\"Determine the most appropriate visual type from specification text\"\"\"\n",
        "    visual_types = {\n",
        "        'chart': ['comparison', 'trend', 'distribution', 'percentage', 'growth', 'decline'],\n",
        "        'map': ['location', 'geographic', 'regional', 'spatial', 'area', 'territory'],\n",
        "        'timeline': ['chronological', 'sequence', 'history', 'progression', 'development'],\n",
        "        'diagram': ['process', 'flow', 'relationship', 'structure', 'organization', 'hierarchy'],\n",
        "        'infographic': ['statistics', 'facts', 'overview', 'summary', 'highlights']\n",
        "    }\n",
        "\n",
        "    # Count matches for each type\n",
        "    scores = {v_type: 0 for v_type in visual_types}\n",
        "\n",
        "    for v_type, keywords in visual_types.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword.lower() in spec_text.lower():\n",
        "                scores[v_type] += 1\n",
        "\n",
        "    # Get the type with highest score\n",
        "    max_score = max(scores.values())\n",
        "    if max_score == 0:\n",
        "        return \"chart\"  # Default\n",
        "\n",
        "    # Return the type with highest score\n",
        "    return max(scores.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "def extract_title(spec_text):\n",
        "    \"\"\"Extract a suitable title for the visual from specification text\"\"\"\n",
        "    # Look for explicit title patterns\n",
        "    title_patterns = [\n",
        "        r'Title:\\s*\"([^\"]+)\"',\n",
        "        r'Title:\\s*(.+?)(?:\\n|$)',\n",
        "        r'titled\\s*\"([^\"]+)\"',\n",
        "        r'titled\\s*(.+?)(?:\\n|$)'\n",
        "    ]\n",
        "\n",
        "    for pattern in title_patterns:\n",
        "        match = re.search(pattern, spec_text)\n",
        "        if match:\n",
        "            return match.group(1).strip()\n",
        "\n",
        "    # If no explicit title, extract the first sentence or phrase\n",
        "    first_line = spec_text.split('\\n')[0].strip()\n",
        "    if len(first_line) > 50:  # Too long for a title\n",
        "        first_line = first_line[:50].strip() + '...'\n",
        "\n",
        "    return first_line\n",
        "\n",
        "def extract_data_needs(spec_text):\n",
        "    \"\"\"Extract data requirements from the visual specification\"\"\"\n",
        "    data_indicators = [\n",
        "        r'Data needed:(.*?)(?:\\n\\n|\\Z)',\n",
        "        r'Data requirements:(.*?)(?:\\n\\n|\\Z)',\n",
        "        r'Required data:(.*?)(?:\\n\\n|\\Z)',\n",
        "        r'Data points:(.*?)(?:\\n\\n|\\Z)'\n",
        "    ]\n",
        "\n",
        "    for pattern in data_indicators:\n",
        "        match = re.search(pattern, spec_text, re.DOTALL)\n",
        "        if match:\n",
        "            data_text = match.group(1).strip()\n",
        "            # Split into list items if it looks like a list\n",
        "            if '\\n' in data_text:\n",
        "                return [item.strip().lstrip('-•*') for item in data_text.split('\\n') if item.strip()]\n",
        "            return [data_text]\n",
        "\n",
        "    # If no explicit data section, look for data-related terms\n",
        "    data_related = []\n",
        "    sentences = re.split(r'[.!?]\\s+', spec_text)\n",
        "    for sentence in sentences:\n",
        "        if any(term in sentence.lower() for term in ['data', 'statistics', 'numbers', 'figures', 'metrics']):\n",
        "            data_related.append(sentence.strip())\n",
        "\n",
        "    return data_related if data_related else [\"No specific data requirements identified\"]\n",
        "\n",
        "def detect_style_preference(task_text):\n",
        "    \"\"\"Detect preferred writing style from task description\"\"\"\n",
        "    style_indicators = {\n",
        "        'academic': ['research', 'scholarly', 'academic', 'thesis', 'dissertation', 'analysis'],\n",
        "        'journalistic': ['news', 'article', 'report', 'coverage', 'journalism'],\n",
        "        'analytical': ['analyze', 'evaluate', 'assess', 'implications', 'critical'],\n",
        "        'narrative': ['story', 'narrative', 'experience', 'personal', 'journey']\n",
        "    }\n",
        "\n",
        "    scores = {style: 0 for style in style_indicators}\n",
        "\n",
        "    for style, keywords in style_indicators.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword.lower() in task_text.lower():\n",
        "                scores[style] += 1\n",
        "\n",
        "    max_score = max(scores.values())\n",
        "    if max_score == 0:\n",
        "        return None  # No clear preference detected\n",
        "\n",
        "    # Return style with highest score\n",
        "    return max(scores.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "def detect_audience(task_text):\n",
        "    \"\"\"Detect target audience from task description\"\"\"\n",
        "    audience_indicators = {\n",
        "        'general': ['general', 'public', 'audience', 'readers', 'people'],\n",
        "        'expert': ['expert', 'specialist', 'professional', 'advanced', 'technical'],\n",
        "        'student': ['student', 'educational', 'classroom', 'learning', 'teaching'],\n",
        "        'business': ['business', 'executive', 'management', 'corporate', 'stakeholder']\n",
        "    }\n",
        "\n",
        "    scores = {audience: 0 for audience in audience_indicators}\n",
        "\n",
        "    for audience, keywords in audience_indicators.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword.lower() in task_text.lower():\n",
        "                scores[audience] += 1\n",
        "\n",
        "    max_score = max(scores.values())\n",
        "    if max_score == 0:\n",
        "        return None  # No clear audience detected\n",
        "\n",
        "    # Return audience with highest score\n",
        "    return max(scores.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "def determine_structure(analysis_text):\n",
        "    \"\"\"Determine optimal essay structure based on analysis text\"\"\"\n",
        "    structure_indicators = {\n",
        "        'chronological': ['timeline', 'history', 'evolution', 'progression', 'over time', 'chronological'],\n",
        "        'compare-contrast': ['comparison', 'contrast', 'differences', 'similarities', 'versus', 'both'],\n",
        "        'problem-solution': ['problem', 'solution', 'challenge', 'resolve', 'address', 'overcome'],\n",
        "        'cause-effect': ['cause', 'effect', 'result', 'impact', 'consequence', 'led to'],\n",
        "        'thesis-antithesis-synthesis': ['argument', 'counterargument', 'thesis', 'antithesis', 'synthesis', 'dialectic']\n",
        "    }\n",
        "\n",
        "    scores = {structure: 0 for structure in structure_indicators}\n",
        "\n",
        "    for structure, keywords in structure_indicators.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword.lower() in analysis_text.lower():\n",
        "                scores[structure] += 1\n",
        "\n",
        "    max_score = max(scores.values())\n",
        "    if max_score == 0:\n",
        "        return 'thesis-antithesis-synthesis'  # Default to a common structure\n",
        "\n",
        "    # Return structure with highest score\n",
        "    return max(scores.items(), key=lambda x: x[1])[0]"
      ],
      "metadata": {
        "id": "N-C5RcysXX2b"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4f51c668222"
      },
      "source": [
        "### Define node functions for each stage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "75c8d7021369"
      },
      "outputs": [],
      "source": [
        "# Generate an outline for the essay\n",
        "# Initialize both models\n",
        "import json\n",
        "google_model = ChatGoogleGenerativeAI(model=MODEL_ID, temperature=0)\n",
        "groq_model = ChatGroq(model_name=\"qwen-qwq-32b\", temperature=0)\n",
        "\n",
        "# Create a model with fallback\n",
        "model = groq_model.with_fallbacks([google_model])\n",
        "\n",
        "def plan_node(state: AgentState):\n",
        "    try:\n",
        "        messages = [SystemMessage(content=PLAN_PROMPT), HumanMessage(content=state[\"task\"])]\n",
        "        response = model.invoke(messages)\n",
        "        return {\"plan\": response.content}\n",
        "    except Exception as e:\n",
        "        print(f\"Error in plan_node: {e}\")\n",
        "        return {\"plan\": \"Default plan: Introduction, Body, Conclusion\"}\n",
        "\n",
        "\n",
        "# Conducts research based on the generated plan and web search results\n",
        "def research_plan_node(state: AgentState):\n",
        "    queries = model.with_structured_output(Queries).invoke(\n",
        "        [\n",
        "            SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
        "            HumanMessage(content=state[\"task\"]),\n",
        "        ]\n",
        "    )\n",
        "    content = state[\"content\"] or []\n",
        "    for q in queries.queries:\n",
        "        # Added a sleep to avoid hitting rate limits\n",
        "        time.sleep(3)\n",
        "        response = tavily.search(query=q, max_results=2)\n",
        "        for r in response[\"results\"]:\n",
        "            content.append(r[\"content\"])\n",
        "    return {\"content\": content}\n",
        "\n",
        "\n",
        "# Generates a draft based on the content and plan\n",
        "def generation_node(state: AgentState):\n",
        "    content = \"\\n\\n\".join(state[\"content\"] or [])\n",
        "    user_message = HumanMessage(\n",
        "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\"\n",
        "    )\n",
        "    messages = [\n",
        "        SystemMessage(content=WRITER_PROMPT.format(content=content)),\n",
        "        user_message,\n",
        "    ]\n",
        "        # Added a sleep to avoid hitting rate limits\n",
        "    time.sleep(3)\n",
        "    response = model.invoke(messages)\n",
        "    return {\n",
        "        \"draft\": response.content,\n",
        "        \"revision_number\": state.get(\"revision_number\", 1) + 1,\n",
        "    }\n",
        "\n",
        "\n",
        "# Provides feedback or critique on the draft\n",
        "def reflection_node(state: AgentState):\n",
        "    messages = [\n",
        "        SystemMessage(content=REFLECTION_PROMPT),\n",
        "        HumanMessage(content=state[\"draft\"]),\n",
        "    ]\n",
        "    try:\n",
        "              # Added a sleep to avoid hitting rate limits\n",
        "        time.sleep(3)\n",
        "        response = model.invoke(messages)\n",
        "    except Exception as e:\n",
        "        print(f\"Error encountered, using fallback mechanism: {e}\")\n",
        "        # The fallback will be handled automatically by the with_fallbacks mechanism\n",
        "        time.sleep(3)\n",
        "        response = model.invoke(messages)\n",
        "    return {\"critique\": response.content}\n",
        "\n",
        "\n",
        "# Conducts research based on the critique\n",
        "def research_critique_node(state: AgentState):\n",
        "    queries = model.with_structured_output(Queries).invoke(\n",
        "        [\n",
        "            SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
        "            HumanMessage(content=state[\"critique\"]),\n",
        "        ]\n",
        "    )\n",
        "    content = state[\"content\"] or []\n",
        "    for q in queries.queries:\n",
        "              # Added a sleep to avoid hitting rate limits\n",
        "        time.sleep(3)\n",
        "        response = tavily.search(query=q, max_results=1)\n",
        "        for r in response[\"results\"]:\n",
        "            content.append(r[\"content\"])\n",
        "    return {\"content\": content}\n",
        "\n",
        "\n",
        "# Determines whether the critique and research cycle should\n",
        "# continue based on the number of revisions\n",
        "def should_continue(state):\n",
        "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
        "        return END\n",
        "    return \"reflect\"\n",
        "\n",
        "\n",
        "# Advanced research capabilities\n",
        "def advanced_research_node(state: AgentState):\n",
        "    # Extract key entities and concepts from the task/plan\n",
        "    entity_extraction = model.invoke([\n",
        "        SystemMessage(content=\"Extract key entities, concepts, and time periods from this text:\"),\n",
        "        HumanMessage(content=state[\"task\"] + \"\\n\" + state[\"plan\"])\n",
        "    ])\n",
        "\n",
        "    # Generate diverse query strategies (definitions, statistics, perspectives, etc.)\n",
        "    query_types = [\"factual overview\", \"statistics and data\", \"expert opinions\",\n",
        "                   \"opposing viewpoints\", \"historical context\", \"recent developments\"]\n",
        "\n",
        "    content = state[\"content\"] or []\n",
        "    entities = extract_entities(entity_extraction.content)\n",
        "\n",
        "    for entity in entities:\n",
        "        for query_type in query_types:\n",
        "            query = f\"{entity} {query_type}\"\n",
        "            response = tavily.search(query=query, max_results=1)\n",
        "            for r in response[\"results\"]:\n",
        "                content.append({\n",
        "                    \"content\": r[\"content\"],\n",
        "                    \"source\": r[\"url\"],\n",
        "                    \"query_type\": query_type,\n",
        "                    \"entity\": entity\n",
        "                })\n",
        "\n",
        "    return {\"content\": content}\n",
        "\n",
        "# Fact checking and Citation Integration\n",
        "def fact_check_node(state: AgentState):\n",
        "    # Extract claims from the draft\n",
        "    claims_extraction = model.invoke([\n",
        "        SystemMessage(content=\"Extract all factual claims from this essay:\"),\n",
        "        HumanMessage(content=state[\"draft\"])\n",
        "    ])\n",
        "\n",
        "    claims = parse_claims(claims_extraction.content)\n",
        "    verified_claims = []\n",
        "\n",
        "    for claim in claims:\n",
        "        # Search for evidence\n",
        "        evidence = tavily.search(query=claim, max_results=1)\n",
        "\n",
        "        # Evaluate if the claim is supported by evidence\n",
        "        verification = model.invoke([\n",
        "            SystemMessage(content=\"Determine if this claim is supported by the evidence provided:\"),\n",
        "            HumanMessage(content=f\"Claim: {claim}\\n\\nEvidence:\\n{json.dumps(evidence)}\")\n",
        "        ])\n",
        "\n",
        "        verified_claims.append({\n",
        "            \"claim\": claim,\n",
        "            \"verification\": verification.content,\n",
        "            \"sources\": [r[\"url\"] for r in evidence[\"results\"]]\n",
        "        })\n",
        "\n",
        "    return {\"fact_check\": verified_claims}\n",
        "\n",
        "# Multi perspective Analysis\n",
        "def perspective_analysis_node(state: AgentState):\n",
        "    perspectives = [\n",
        "        \"Economic impact perspective\",\n",
        "        \"Environmental perspective\",\n",
        "        \"Social impact perspective\",\n",
        "        \"Political perspective\",\n",
        "        \"Scientific perspective\"\n",
        "    ]\n",
        "\n",
        "    analysis = {}\n",
        "\n",
        "    for perspective in perspectives:\n",
        "        analysis[perspective] = model.invoke([\n",
        "            SystemMessage(content=f\"Analyze the topic from a {perspective}:\"),\n",
        "            HumanMessage(content=state[\"task\"])\n",
        "        ]).content\n",
        "\n",
        "    return {\"perspectives\": analysis}\n",
        "\n",
        "# Style and tone Adaptation\n",
        "def style_adaptation_node(state: AgentState):\n",
        "    try:\n",
        "        # Detect or request a style/tone preference\n",
        "        styles = {\n",
        "            \"academic\": \"Formal, structured, evidence-based with sophisticated vocabulary\",\n",
        "            \"journalistic\": \"Clear, factual, engaging with strong narrative flow\",\n",
        "            \"analytical\": \"Logical, methodical, focused on insights and implications\",\n",
        "            \"narrative\": \"Story-driven, vivid descriptions, emotional resonance\"\n",
        "        }\n",
        "\n",
        "        # Either detect from the task or use a default\n",
        "        style_name = detect_style_preference(state[\"task\"]) or \"academic\"\n",
        "        style_guide = styles[style_name]\n",
        "\n",
        "        return {\"style_preference\": style_name, \"style_guide\": style_guide}\n",
        "    except Exception as e:\n",
        "        print(f\"Error in style_adaptation_node: {e}\")\n",
        "        return {\"style_preference\": \"academic\", \"style_guide\": \"Formal, structured, evidence-based\"}\n",
        "\n",
        "def visual_planning_node(state: AgentState):\n",
        "    # Identify opportunities for visual elements\n",
        "    visual_opportunities = model.invoke([\n",
        "        SystemMessage(content=\"Identify 3-5 key points from this content that would benefit from visual representation (charts, maps, timelines, etc.):\"),\n",
        "        HumanMessage(content=state[\"draft\"])\n",
        "    ]).content\n",
        "\n",
        "    # Generate specifications for each visual\n",
        "    visual_specs = []\n",
        "    for opportunity in parse_opportunities(visual_opportunities):\n",
        "        spec = model.invoke([\n",
        "            SystemMessage(content=\"Create a detailed specification for a visual element:\"),\n",
        "            HumanMessage(content=f\"Topic: {opportunity}\")\n",
        "        ]).content\n",
        "\n",
        "        visual_specs.append({\n",
        "            \"type\": determine_visual_type(spec),\n",
        "            \"title\": extract_title(spec),\n",
        "            \"description\": spec,\n",
        "            \"data_needed\": extract_data_needs(spec)\n",
        "        })\n",
        "\n",
        "    return {\"visual_elements\": visual_specs}\n",
        "\n",
        "\n",
        "# Adaptive learning from user feedback\n",
        "def feedback_integration_node(state: AgentState, user_feedback=None):\n",
        "    if not user_feedback:\n",
        "        return state\n",
        "\n",
        "    # Analyze feedback to identify improvement areas\n",
        "    feedback_analysis = model.invoke([\n",
        "        SystemMessage(content=\"Analyze this feedback and identify specific areas for improvement:\"),\n",
        "        HumanMessage(content=user_feedback)\n",
        "    ]).content\n",
        "\n",
        "    # Update the writing approach based on feedback\n",
        "    learning = model.invoke([\n",
        "        SystemMessage(content=\"Based on this feedback analysis, provide specific writing adjustments:\"),\n",
        "        HumanMessage(content=feedback_analysis)\n",
        "    ]).content\n",
        "\n",
        "    return {\"feedback_analysis\": feedback_analysis, \"writing_adjustments\": learning}\n",
        "\n",
        "# Ethical Consideration and Bias Detection\n",
        "def bias_detection_node(state: AgentState):\n",
        "    # Analyze content for potential biases\n",
        "    bias_analysis = model.invoke([\n",
        "        SystemMessage(content=\"Analyze this content for potential biases, one-sided perspectives, or ethical considerations:\"),\n",
        "        HumanMessage(content=state[\"draft\"])\n",
        "    ]).content\n",
        "\n",
        "    # Generate suggestions for addressing identified issues\n",
        "    if \"No significant bias detected\" not in bias_analysis:\n",
        "        bias_mitigation = model.invoke([\n",
        "            SystemMessage(content=\"Suggest specific revisions to address these potential biases:\"),\n",
        "            HumanMessage(content=bias_analysis)\n",
        "        ]).content\n",
        "\n",
        "        return {\"bias_analysis\": bias_analysis, \"bias_mitigation\": bias_mitigation}\n",
        "\n",
        "    return {\"bias_analysis\": \"No significant bias detected\"}\n",
        "\n",
        "# Audience Adaptation\n",
        "def audience_adaptation_node(state: AgentState):\n",
        "    try:\n",
        "        # Detect or define target audience characteristics\n",
        "        audiences = {\n",
        "            \"general\": \"Wide range of knowledge levels, diverse backgrounds\",\n",
        "            \"expert\": \"Specialized knowledge, familiar with technical terms\",\n",
        "            \"student\": \"Learning-focused, may need scaffolding of concepts\",\n",
        "            \"business\": \"Application-oriented, interested in implications\"\n",
        "        }\n",
        "\n",
        "        # Either detect from the task or use a default\n",
        "        audience_type = detect_audience(state[\"task\"]) or \"general\"\n",
        "        audience_profile = audiences[audience_type]\n",
        "\n",
        "        # Adapt content complexity and focus accordingly\n",
        "        adaptation_guide = model.invoke([\n",
        "            SystemMessage(content=f\"Create guidelines for adapting this content to a {audience_type} audience ({audience_profile}):\"),\n",
        "            HumanMessage(content=state[\"draft\"] if \"draft\" in state else state[\"task\"])\n",
        "        ]).content\n",
        "\n",
        "        return {\"audience_type\": audience_type, \"adaptation_guide\": adaptation_guide}\n",
        "    except Exception as e:\n",
        "        print(f\"Error in audience_adaptation_node: {e}\")\n",
        "        return {\"audience_type\": \"general\", \"adaptation_guide\": \"Focus on clarity and accessibility\"}\n",
        "\n",
        "\n",
        "# Dynamic Structure Adaptation\n",
        "def structure_optimization_node(state: AgentState):\n",
        "    # Analyze content to determine optimal structure\n",
        "    structure_analysis = model.invoke([\n",
        "        SystemMessage(content=\"Analyze this content and recommend the optimal essay structure:\"),\n",
        "        HumanMessage(content=\"\\n\".join(state[\"content\"]))\n",
        "    ]).content\n",
        "\n",
        "    # Generate a structural outline\n",
        "    structure_types = [\"chronological\", \"compare-contrast\", \"problem-solution\", \"cause-effect\", \"thesis-antithesis-synthesis\"]\n",
        "    recommended_structure = determine_structure(structure_analysis)\n",
        "\n",
        "    structure_template = model.invoke([\n",
        "        SystemMessage(content=f\"Create a detailed outline template for a {recommended_structure} essay structure:\"),\n",
        "        HumanMessage(content=state[\"task\"])\n",
        "    ]).content\n",
        "\n",
        "    return {\"recommended_structure\": recommended_structure, \"structure_template\": structure_template}\n",
        "\n",
        "# Source Quality Evaluation\n",
        "def source_evaluation_node(state: AgentState):\n",
        "    content = state[\"content\"]\n",
        "    evaluated_content = []\n",
        "\n",
        "    # Initialize the model inside the function\n",
        "    google_model = ChatGoogleGenerativeAI(model=MODEL_ID, temperature=0)\n",
        "    groq_model = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0)\n",
        "    model = groq_model.with_fallbacks([google_model])\n",
        "\n",
        "    for item in content:\n",
        "        if isinstance(item, dict) and \"source\" in item:\n",
        "            # Evaluate source credibility\n",
        "            source_eval = model.invoke([\n",
        "                SystemMessage(content=\"Evaluate the credibility of this source based on its URL and content:\"),\n",
        "                HumanMessage(content=f\"URL: {item['source']}\\nContent: {item['content']}\")\n",
        "            ]).content\n",
        "\n",
        "            item[\"source_evaluation\"] = {\n",
        "                \"credibility_score\": extract_score(source_eval),\n",
        "                \"credibility_notes\": source_eval\n",
        "            }\n",
        "\n",
        "        evaluated_content.append(item)\n",
        "\n",
        "    # Filter or flag low-credibility sources\n",
        "    return {\"content\": evaluated_content}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def node_wrapper(func):\n",
        "    \"\"\"Wrapper to ensure node functions never return None\"\"\"\n",
        "    def wrapper(state):\n",
        "        try:\n",
        "            # Introduce a delay before each node execution\n",
        "            time.sleep(5)  # Adjust the delay as needed\n",
        "            result = func(state)\n",
        "            if result is None:\n",
        "                print(f\"WARNING: {func.__name__} returned None, using empty dict instead\")\n",
        "                return {}  # Return empty dict instead of None\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR in {func.__name__}: {e}\")\n",
        "            # Return empty dict to continue execution\n",
        "            return {}\n",
        "    return wrapper\n",
        "\n",
        "# Apply wrapper to all node functions\n",
        "planner = node_wrapper(plan_node)\n",
        "structure_optimizer = node_wrapper(structure_optimization_node)\n",
        "audience_adapter = node_wrapper(audience_adaptation_node)\n",
        "style_adapter = node_wrapper(style_adaptation_node)\n",
        "advanced_researcher = node_wrapper(advanced_research_node)\n",
        "#source_evaluator = node_wrapper(source_evaluation_node)\n",
        "perspective_analyzer = node_wrapper(perspective_analysis_node)\n",
        "generate = node_wrapper(generation_node)\n",
        "visual_planner = node_wrapper(visual_planning_node)\n",
        "reflect = node_wrapper(reflection_node)\n",
        "fact_checker = node_wrapper(fact_check_node)\n",
        "bias_detector = node_wrapper(bias_detection_node)\n",
        "research_critique = node_wrapper(research_critique_node)"
      ],
      "metadata": {
        "id": "D4E1CrWchWnp"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48569416595a"
      },
      "source": [
        "### Define and compile the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "86567ad87aa2"
      },
      "outputs": [],
      "source": [
        "# Enhanced graph with new nodes\n",
        "builder = StateGraph(AgentState)\n",
        "\n",
        "# Planning phase\n",
        "builder.add_node(\"planner\", plan_node)\n",
        "builder.add_node(\"structure_optimizer\", structure_optimization_node)\n",
        "builder.add_node(\"audience_adapter\", audience_adaptation_node)\n",
        "builder.add_node(\"style_adapter\", style_adaptation_node)\n",
        "\n",
        "# Research phase\n",
        "builder.add_node(\"advanced_researcher\", advanced_research_node)\n",
        "#builder.add_node(\"source_evaluator\", source_evaluation_node)\n",
        "builder.add_node(\"perspective_analyzer\", perspective_analysis_node)\n",
        "\n",
        "# Generation phase\n",
        "builder.add_node(\"generate\", generation_node)\n",
        "builder.add_node(\"visual_planner\", visual_planning_node)\n",
        "\n",
        "# Evaluation phase\n",
        "builder.add_node(\"reflect\", reflection_node)\n",
        "builder.add_node(\"fact_checker\", fact_check_node)\n",
        "builder.add_node(\"bias_detector\", bias_detection_node)\n",
        "builder.add_node(\"research_critique\", research_critique_node)  # Added the missing node\n",
        "\n",
        "# Define the enhanced workflow\n",
        "builder.set_entry_point(\"planner\")\n",
        "\n",
        "# Planning workflow\n",
        "builder.add_edge(\"planner\", \"structure_optimizer\")\n",
        "builder.add_edge(\"structure_optimizer\", \"audience_adapter\")\n",
        "builder.add_edge(\"audience_adapter\", \"style_adapter\")\n",
        "builder.add_edge(\"style_adapter\", \"advanced_researcher\")\n",
        "\n",
        "# Research workflow\n",
        "builder.add_edge(\"advanced_researcher\", \"perspective_analyzer\")\n",
        "#builder.add_edge(\"source_evaluator\", \"perspective_analyzer\")\n",
        "builder.add_edge(\"perspective_analyzer\", \"generate\")\n",
        "\n",
        "# Generation and evaluation workflow\n",
        "builder.add_edge(\"generate\", \"visual_planner\")\n",
        "builder.add_edge(\"visual_planner\", \"fact_checker\")\n",
        "builder.add_edge(\"fact_checker\", \"bias_detector\")\n",
        "builder.add_edge(\"bias_detector\", \"reflect\")\n",
        "\n",
        "# Add conditional edges for task continuation or end\n",
        "builder.add_conditional_edges(\n",
        "    \"bias_detector\",\n",
        "    should_continue,\n",
        "    {END: END, \"reflect\": \"reflect\"}\n",
        ")\n",
        "\n",
        "# Revision loop\n",
        "builder.add_edge(\"reflect\", \"research_critique\")\n",
        "builder.add_edge(\"research_critique\", \"generate\")\n",
        "\n",
        "# Compile the enhanced graph\n",
        "enhanced_graph = builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44d87b0a2052"
      },
      "source": [
        "### Show the compiled graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "9c3170874384",
        "outputId": "86cb6225-4ce8-4226-8be9-5ad1c6c09775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "Image(enhanced_graph.get_graph().draw_mermaid_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c95bebc7e74c"
      },
      "source": [
        "### Run the agent - write on!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "2a849843b454",
        "outputId": "f345e2c1-44b0-422a-96a4-50b6be9584ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# planner"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n<think>\nOkay, the user is asking about the impacts of Hurricane Helene and Hurricane Milton in 2024. First, I need to check if these hurricanes actually occurred in 2024. Wait, 2024 hasn't happened yet, so maybe they're hypothetical or from a fictional scenario. The user might be referring to a projected or speculative event, perhaps for a class assignment or a creative project. \n\nI should start by clarifying that since 2024 is in the future, the information isn't based on real events. But the user still wants an outline, so I'll proceed under the assumption that these are fictional hurricanes for the purpose of the essay. \n\nThe outline needs to cover both hurricanes, so I should structure it to compare and contrast their impacts. Maybe start with an introduction that sets the context of the fictional scenario. Then, separate sections for each hurricane, detailing their paths, intensity, and specific impacts like casualties, economic damage, environmental effects, and responses. \n\nIncluding a comparative analysis section would help highlight differences and similarities. Also, a section on lessons learned or future preparedness could be useful. The conclusion should summarize key points and reflect on the importance of disaster preparedness.\n\nI should also add notes to the user, advising them to use real data if possible, or to clearly state that the scenario is fictional. Maybe suggest including sources if they're using real historical data as a basis. Also, remind them to check the latest information since the user might have a typo in the year. \n\nWait, the user might have meant 2023 or another year. But since they specified 2024, I'll stick with that. Need to make sure the outline is balanced between the two hurricanes, ensuring each gets equal attention. Maybe include subsections for each impact category under each hurricane. \n\nAlso, environmental impacts could include things like deforestation, wildlife disruption, and long-term ecological changes. Economic impacts might involve infrastructure damage, business losses, and recovery costs. Human impacts would be casualties, displacement, and health issues. \n\nThe comparative analysis should look at factors like the regions affected, the timing of the hurricanes, and the effectiveness of the responses. Maybe one was better prepared than the other, leading to different outcomes. \n\nI should also mention in the notes that the user should verify the existence of these hurricanes and adjust the outline accordingly. If they're real, then the approach would be different, but since 2024 is future, it's safer to treat them as hypothetical. \n\nAlright, structuring the outline with clear headings and subpoints. Making sure each section flows logically from introduction to conclusion. Including notes to guide the user on how to develop each section, emphasizing the need for accurate data and proper citations.\n</think>\n\n### Essay Outline: The Impacts of Hurricane Helene and Hurricane Milton in 2024  \n\n---\n\n#### **I. Introduction**  \n- **Hook**: Briefly introduce the 2024 Atlantic hurricane season as an unusually active or notable year.  \n- **Context**: Mention that Hurricane Helene and Hurricane Milton were two of the most destructive storms of the season.  \n- **Thesis Statement**: While both hurricanes caused significant damage, their impacts varied in terms of geographic reach, human toll, economic consequences, and environmental effects.  \n\n---\n\n#### **II. Background on the Hurricanes**  \n1. **Hurricane Helene**  \n   - Formation and path: Origin, peak intensity (e.g., Category 4), and trajectory (e.g., Caribbean islands, U.S. East Coast).  \n   - Duration and landfall locations.  \n2. **Hurricane Milton**  \n   - Formation and path: Origin, peak intensity (e.g., Category 3), and trajectory (e.g., Gulf of Mexico, Central America).  \n   - Duration and landfall locations.  \n- **Key Difference**: Highlight contrasting paths (e.g., Helene affecting coastal urban areas, Milton impacting rural or less-developed regions).  \n\n---\n\n#### **III. Human and Social Impacts**  \n1. **Hurricane Helene**  \n   - Casualties and injuries.  \n   - Displacement of populations (e.g., evacuation orders, temporary shelters).  \n   - Social disruption (e.g., school closures, healthcare system strain).  \n2. **Hurricane Milton**  \n   - Casualties and injuries (possibly higher due to slower response in remote areas).  \n   - Displacement and challenges in evacuation (e.g., limited infrastructure).  \n   - Cultural impacts (e.g., damage to historical or culturally significant sites).  \n- **Comparison**: Contrast urban vs. rural vulnerability and response capabilities.  \n\n---\n\n#### **IV. Economic Impacts**  \n1. **Hurricane Helene**  \n   - Damage to infrastructure (e.g., flooded cities, destroyed homes, business closures).  \n   - Insurance claims and government aid (e.g., federal disaster relief).  \n   - Long-term economic ripple effects (e.g., tourism decline, supply chain disruptions).  \n2. **Hurricane Milton**  \n   - Agricultural losses (e.g., crop destruction in farming-dependent regions).  \n   - Limited insurance coverage in affected areas, leading to greater financial strain on communities.  \n   - Recovery challenges due to underfunded local governments.  \n- **Comparison**: Urban vs. rural economic resilience and recovery timelines.  \n\n---\n\n#### **V. Environmental Impacts**  \n1. **Hurricane Helene**  \n   - Coastal erosion, saltwater intrusion into freshwater systems.  \n   - Damage to ecosystems (e.g., mangrove destruction, coral reef bleaching).  \n2. **Hurricane Milton**  \n   - Deforestation and landslides in mountainous regions.  \n   - Contamination of water supplies from flooding.  \n- **Commonality**: Both storms exacerbated climate change vulnerabilities (e.g., rising sea levels, warmer ocean temperatures).  \n\n---\n\n#### **VI. Response and Recovery Efforts**  \n1. **Hurricane Helene**  \n   - Effective early warnings and evacuation protocols.  \n   - International aid and NGO involvement.  \n2. **Hurricane Milton**  \n   - Delays in emergency response due to logistical challenges.  \n   - Reliance on local communities for initial recovery efforts.  \n- **Key Takeaway**: Highlight the role of preparedness and resource allocation in mitigating damage.  \n\n---\n\n#### **VII. Comparative Analysis**  \n- **Geographic Differences**: Urban vs. rural vulnerability.  \n- **Climate and Infrastructure**: How building codes, elevation, and disaster planning influenced outcomes.  \n- **Global vs. Local Impacts**: Helene’s international media attention vs. Milton’s underreported crisis.  \n\n---\n\n#### **VIII. Lessons Learned and Future Preparedness**  \n- **Policy Recommendations**: Strengthening early warning systems, improving infrastructure in vulnerable regions.  \n- **Climate Change Context**: Link the storms to broader climate trends (e.g., increased storm intensity).  \n- **Call to Action**: Emphasize the need for equitable disaster response and global cooperation.  \n\n---\n\n#### **IX. Conclusion**  \n- Recap the unique and shared impacts of both hurricanes.  \n- Reiterate the importance of learning from these events to build resilience.  \n- Final thought: A reflection on humanity’s preparedness for future climate-driven disasters.  \n\n---\n\n### **Notes for the Writer**:  \n1. **Data Sources**: Since 2024 is in the future, use hypothetical scenarios based on historical analogs (e.g., reference Hurricane Ian 2022 for Helene, Hurricane Dorian 2019 for Milton).  \n2. **Tone**: Maintain an academic tone but acknowledge the speculative nature of the topic.  \n3. **Maps/Charts**: Suggest including fictional maps showing storm tracks and damage zones.  \n4. **Ethical Consideration**: Clearly state that the hurricanes are fictional to avoid misinformation.  \n5. **Sources**: Cite real studies on hurricane impacts (e.g., IPCC reports, NOAA data) to ground the analysis in reality.  \n\n---\n\nThis outline balances structure with flexibility, allowing the writer to explore both hurricanes’ effects while emphasizing critical analysis of their differences and broader implications. Adjust details based on the essay’s required focus (e.g., environmental science, sociology, policy)."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "\n",
            "WARNING: Node structure_optimizer returned None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# structure_optimizer (returned None)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "\n",
            "WARNING: Node audience_adapter returned None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# audience_adapter (returned None)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "\n",
            "WARNING: Node style_adapter returned None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# style_adapter (returned None)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-af9fe6f1c44b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Stream with comprehensive initial state and error handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menhanced_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2321\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2323\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2324\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    147\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m                 )\n\u001b[1;32m    599\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-e109e46991a6>\u001b[0m in \u001b[0;36madvanced_research_node\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{entity} {query_type}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtavily\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 content.append({\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tavily/tavily.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, query, search_depth, topic, days, max_results, include_domains, exclude_domains, include_answer, include_raw_content, include_images, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \"\"\"\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         response_dict = self._search(query,\n\u001b[0m\u001b[1;32m     97\u001b[0m                                      \u001b[0msearch_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_depth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                      \u001b[0mtopic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tavily/tavily.py\u001b[0m in \u001b[0;36m_search\u001b[0;34m(self, query, search_depth, topic, days, max_results, include_domains, exclude_domains, include_answer, include_raw_content, include_images, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_url\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/search\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Define the topic of the essay\n",
        "ESSAY_TOPIC = \"What were the impacts of Hurricane Helene and Hurricane Milton in 2024?\"\n",
        "\n",
        "# Define a thread configuration with a unique thread ID\n",
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "# Create comprehensive initial state with defaults for all fields\n",
        "initial_state = {\n",
        "    \"task\": ESSAY_TOPIC,\n",
        "    \"max_revisions\": 1,\n",
        "    \"revision_number\": 1,\n",
        "    \"content\": [],\n",
        "    \"plan\": \"\",\n",
        "    \"draft\": \"\",\n",
        "    \"critique\": \"\",\n",
        "    \"perspectives\": {},\n",
        "    \"audience_type\": \"general\",\n",
        "    \"style_preference\": \"academic\",\n",
        "    \"recommended_structure\": \"\",\n",
        "    \"structure_template\": \"\",\n",
        "    \"adaptation_guide\": \"\",\n",
        "    \"style_guide\": \"\",\n",
        "    \"visual_elements\": [],\n",
        "    \"fact_check\": [],\n",
        "    \"bias_analysis\": \"\"\n",
        "}\n",
        "\n",
        "# Stream with comprehensive initial state and error handling\n",
        "for s in enhanced_graph.stream(initial_state, thread):\n",
        "    try:\n",
        "        step = next(iter(s))\n",
        "        if s[step] is None:\n",
        "            print(f\"WARNING: Node {step} returned None\")\n",
        "            display(Markdown(f\"# {step} (returned None)\"))\n",
        "        else:\n",
        "            display(Markdown(f\"# {step}\"))\n",
        "            for key, content in s[step].items():\n",
        "                if key == \"revision_number\":\n",
        "                    display(Markdown(f\"**Revision Number**: {content}\"))\n",
        "                elif isinstance(content, list):\n",
        "                    try:\n",
        "                        for c in content:\n",
        "                            display(Markdown(str(c)))\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error displaying list content: {e}\")\n",
        "                else:\n",
        "                    try:\n",
        "                        display(Markdown(str(content)))\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error displaying content for {key}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in stream processing: {e}\")\n",
        "    print(\"\\n---\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c95d0cd7f6a"
      },
      "source": [
        "### Output the final draft of the essay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "e50e674081f2",
        "outputId": "8269c48c-7294-4f79-c7d1-404d02d70cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### The Devastating Impacts of Hurricane Helene and Hurricane Milton: A Comparative Analysis\nThe impacts of hurricanes on communities can be devastating, causing widespread destruction, loss of life, and long-term economic and environmental damage. Hurricane Helene and Hurricane Milton, which made landfall in 2024, are examples of significant hurricanes that had far-reaching consequences. This essay will examine the environmental, economic, and human impacts of these two hurricanes, highlighting the importance of disaster preparedness and mitigation strategies. Hurricane Helene, in particular, produced widespread and damaging landslides, while Hurricane Milton caused significant structural damage and flash flooding in several areas.\n\n### Environmental and Economic Impacts\nThe environmental effects of Hurricane Helene and Hurricane Milton were severe, with storm surges, flooding, and landslides causing damage to wildlife habitats and ecosystems. Hurricane Helene made landfall in Florida as a Category 4 storm, producing record rainfall and resulting in flash flooding, road washouts, and landslides in several areas. In contrast, Hurricane Milton's outer rainbands moved across the Treasure Coast, causing an EF-0 tornado in Martin and St. Lucie counties and an EF-1 tornado in St. Lucie County, resulting in significant structural damage and vegetative damage. The economic consequences of the hurricanes were also significant, with damage to infrastructure, losses to agriculture and tourism, and disruption of supply chains and trade. The total damage from both hurricanes is likely to exceed $50 billion, making them two of the costliest hurricanes in history.\n\n### Human Impacts and Conclusion\nThe human consequences of Hurricane Helene and Hurricane Milton were also severe, with loss of life, displacement, and psychological trauma reported in several areas. The response efforts of governments, NGOs, and local communities were critical in reducing the impacts of the hurricanes, with evacuation orders, emergency supplies, and shelter provided to those in need. In conclusion, the impacts of Hurricane Helene and Hurricane Milton highlight the importance of disaster preparedness and mitigation strategies in reducing the effects of hurricanes. By understanding the environmental, economic, and human impacts of these hurricanes, communities can better prepare for future disasters, reducing the risk of loss of life, property damage, and social disruption. Ultimately, the key to mitigating the effects of hurricanes lies in a combination of preparedness, planning, and proactive measures to reduce the vulnerability of communities to these powerful storms."
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(s[\"generate\"][\"draft\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c01d26c8df5b"
      },
      "source": [
        "## Additional Resources\n",
        "\n",
        "- [Google Cloud Generative AI repository on GitHub](https://github.com/GoogleCloudPlatform/generative-ai/)\n",
        "- [Gemini API in Google AI Studio](https://ai.google.dev/gemini-api/docs)\n",
        "- [Gemini API in Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/overview)\n",
        "- [LangGraph tutorials](https://langchain-ai.github.io/langgraph/tutorials/)\n",
        "- [DeepLearning.AI course on AI Agents in LangGraph](https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ai_agents_for_engineers.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}